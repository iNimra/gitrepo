{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata,norm\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrices import confusion_matrix,f1_score,precision_score,recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [ \"x-axis\", \"y-axis\", \"z-axis\",'unknow',\"activity\"]\n",
    "df = pd.read_csv(\"e02-ss2.csv\")\n",
    "df=df.dropna()\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count no of classes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call attending    10040\n",
       "eating             9720\n",
       "reading            8880\n",
       "drinking           4840\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(df.iloc[:,0:-1])\n",
    "Y=np.asarray(df.iloc[:,-1])\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y=le.fit_transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)`n`m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\umair\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=RandomForestClassifier()\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre= tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746583401212779"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverse encoded labels... #inverse transform means transform labels back to original encoding#label encoding means convert label into numeric form i.e machine readable form.ML algos can then decided in a better way on how those labels must be operated.It is important preprocessing steps for structured dataset in supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_inver=le.inverse_transform(pre)\n",
    "y_test_inver=le.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes and insert data into it.......//True label means outcome of the targetted.In supervised learning target label known as trainig dataset..target means whatever the output  of input variables.labels are the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "df1[\"predicted_lable\"]=pre_inver\n",
    "df1[\"true_lable\"]=y_test_inver\n",
    "# df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22431, 1, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len(np.unique(Y)))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\umair\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 500)            1010000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 350)            1191400   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               180400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 2,382,204\n",
      "Trainable params: 2,382,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(500, input_shape= (1, 4),return_sequences=True))\n",
    "model.add(keras.layers.LSTM(350, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(100))\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20187 samples, validate on 2244 samples\n",
      "Epoch 1/100\n",
      "20187/20187 [==============================] - 86s 4ms/sample - loss: 1.3403 - acc: 0.3116 - val_loss: 1.3021 - val_acc: 0.3672\n",
      "Epoch 2/100\n",
      "20187/20187 [==============================] - 80s 4ms/sample - loss: 1.2490 - acc: 0.3863 - val_loss: 1.1946 - val_acc: 0.4180\n",
      "Epoch 3/100\n",
      "20187/20187 [==============================] - 81s 4ms/sample - loss: 1.1599 - acc: 0.4352 - val_loss: 1.1225 - val_acc: 0.4492\n",
      "Epoch 4/100\n",
      "20187/20187 [==============================] - 80s 4ms/sample - loss: 1.0512 - acc: 0.4959 - val_loss: 0.9902 - val_acc: 0.5258\n",
      "Epoch 5/100\n",
      "20187/20187 [==============================] - 81s 4ms/sample - loss: 0.9500 - acc: 0.5433 - val_loss: 0.9064 - val_acc: 0.5575\n",
      "Epoch 6/100\n",
      "20187/20187 [==============================] - 81s 4ms/sample - loss: 0.8862 - acc: 0.5706 - val_loss: 0.8674 - val_acc: 0.5793\n",
      "Epoch 7/100\n",
      "20187/20187 [==============================] - 84s 4ms/sample - loss: 0.8624 - acc: 0.5823 - val_loss: 0.8382 - val_acc: 0.5954\n",
      "Epoch 8/100\n",
      "20187/20187 [==============================] - 93s 5ms/sample - loss: 0.8386 - acc: 0.5929 - val_loss: 0.8372 - val_acc: 0.5914\n",
      "Epoch 9/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.8221 - acc: 0.5971 - val_loss: 0.8336 - val_acc: 0.5869\n",
      "Epoch 10/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.8219 - acc: 0.5959 - val_loss: 0.8160 - val_acc: 0.5949\n",
      "Epoch 11/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.8105 - acc: 0.5994 - val_loss: 0.7950 - val_acc: 0.6061\n",
      "Epoch 12/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.8010 - acc: 0.6020 - val_loss: 0.8063 - val_acc: 0.5918\n",
      "Epoch 13/100\n",
      "20187/20187 [==============================] - 89s 4ms/sample - loss: 0.7992 - acc: 0.6009 - val_loss: 0.8574 - val_acc: 0.5749\n",
      "Epoch 14/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7928 - acc: 0.6059 - val_loss: 0.8298 - val_acc: 0.5807\n",
      "Epoch 15/100\n",
      "20187/20187 [==============================] - 89s 4ms/sample - loss: 0.7977 - acc: 0.6059 - val_loss: 0.8041 - val_acc: 0.5998\n",
      "Epoch 16/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7818 - acc: 0.6114 - val_loss: 0.7875 - val_acc: 0.6038\n",
      "Epoch 17/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7843 - acc: 0.6093 - val_loss: 0.7687 - val_acc: 0.6172\n",
      "Epoch 18/100\n",
      "20187/20187 [==============================] - 2050s 102ms/sample - loss: 0.7800 - acc: 0.6089 - val_loss: 0.7672 - val_acc: 0.6114\n",
      "Epoch 19/100\n",
      "20187/20187 [==============================] - 77s 4ms/sample - loss: 0.7718 - acc: 0.6145 - val_loss: 0.7679 - val_acc: 0.6110\n",
      "Epoch 20/100\n",
      "20187/20187 [==============================] - 78s 4ms/sample - loss: 0.7960 - acc: 0.6050 - val_loss: 0.7937 - val_acc: 0.6007\n",
      "Epoch 21/100\n",
      "20187/20187 [==============================] - 77s 4ms/sample - loss: 0.7723 - acc: 0.6153 - val_loss: 0.7576 - val_acc: 0.6159\n",
      "Epoch 22/100\n",
      "20187/20187 [==============================] - 76s 4ms/sample - loss: 0.7711 - acc: 0.6131 - val_loss: 0.7839 - val_acc: 0.6087\n",
      "Epoch 23/100\n",
      "20187/20187 [==============================] - 76s 4ms/sample - loss: 0.7749 - acc: 0.6122 - val_loss: 0.7900 - val_acc: 0.6052\n",
      "Epoch 24/100\n",
      "20187/20187 [==============================] - 76s 4ms/sample - loss: 0.7656 - acc: 0.6174 - val_loss: 0.7592 - val_acc: 0.6159\n",
      "Epoch 25/100\n",
      "20187/20187 [==============================] - 75s 4ms/sample - loss: 0.7625 - acc: 0.6172 - val_loss: 0.8040 - val_acc: 0.5998\n",
      "Epoch 26/100\n",
      "20187/20187 [==============================] - 77s 4ms/sample - loss: 0.7679 - acc: 0.6170 - val_loss: 0.7601 - val_acc: 0.6145\n",
      "Epoch 27/100\n",
      "20187/20187 [==============================] - 76s 4ms/sample - loss: 0.7577 - acc: 0.6194 - val_loss: 0.7537 - val_acc: 0.6159\n",
      "Epoch 28/100\n",
      "20187/20187 [==============================] - 76s 4ms/sample - loss: 0.7731 - acc: 0.6135 - val_loss: 0.7543 - val_acc: 0.6159\n",
      "Epoch 29/100\n",
      "20187/20187 [==============================] - 77s 4ms/sample - loss: 0.7541 - acc: 0.6212 - val_loss: 0.7612 - val_acc: 0.6168\n",
      "Epoch 30/100\n",
      "20187/20187 [==============================] - 63756s 3s/sample - loss: 0.7617 - acc: 0.6182 - val_loss: 0.8182 - val_acc: 0.5860\n",
      "Epoch 31/100\n",
      "20187/20187 [==============================] - 92s 5ms/sample - loss: 0.7582 - acc: 0.6189 - val_loss: 0.8062 - val_acc: 0.5980\n",
      "Epoch 32/100\n",
      "20187/20187 [==============================] - 91s 5ms/sample - loss: 0.7630 - acc: 0.6185 - val_loss: 0.7462 - val_acc: 0.6203\n",
      "Epoch 33/100\n",
      "20187/20187 [==============================] - 87s 4ms/sample - loss: 0.7522 - acc: 0.6228 - val_loss: 0.7540 - val_acc: 0.6203\n",
      "Epoch 34/100\n",
      "20187/20187 [==============================] - 88s 4ms/sample - loss: 0.7587 - acc: 0.6190 - val_loss: 0.7530 - val_acc: 0.6190\n",
      "Epoch 35/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7527 - acc: 0.6223 - val_loss: 0.7527 - val_acc: 0.6119\n",
      "Epoch 36/100\n",
      "20187/20187 [==============================] - 87s 4ms/sample - loss: 0.7584 - acc: 0.6198 - val_loss: 0.8539 - val_acc: 0.5798\n",
      "Epoch 37/100\n",
      "20187/20187 [==============================] - 84s 4ms/sample - loss: 0.7584 - acc: 0.6199 - val_loss: 0.7585 - val_acc: 0.6123\n",
      "Epoch 38/100\n",
      "20187/20187 [==============================] - 86s 4ms/sample - loss: 0.7463 - acc: 0.6245 - val_loss: 0.7636 - val_acc: 0.6136\n",
      "Epoch 39/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7513 - acc: 0.6204 - val_loss: 0.7428 - val_acc: 0.6230\n",
      "Epoch 40/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7581 - acc: 0.6201 - val_loss: 0.7496 - val_acc: 0.6172\n",
      "Epoch 41/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7414 - acc: 0.6259 - val_loss: 0.7779 - val_acc: 0.6029\n",
      "Epoch 42/100\n",
      "20187/20187 [==============================] - 88s 4ms/sample - loss: 0.7393 - acc: 0.6274 - val_loss: 0.7339 - val_acc: 0.6221\n",
      "Epoch 43/100\n",
      "20187/20187 [==============================] - 90s 4ms/sample - loss: 0.7435 - acc: 0.6259 - val_loss: 0.7603 - val_acc: 0.6132\n",
      "Epoch 44/100\n",
      "20187/20187 [==============================] - 89s 4ms/sample - loss: 0.7490 - acc: 0.6220 - val_loss: 0.7872 - val_acc: 0.5980\n",
      "Epoch 45/100\n",
      "20187/20187 [==============================] - 89s 4ms/sample - loss: 0.7468 - acc: 0.6250 - val_loss: 0.7408 - val_acc: 0.6230\n",
      "Epoch 46/100\n",
      "20187/20187 [==============================] - 91s 4ms/sample - loss: 0.7457 - acc: 0.6259 - val_loss: 0.7410 - val_acc: 0.6194\n",
      "Epoch 47/100\n",
      "20187/20187 [==============================] - 94s 5ms/sample - loss: 0.7401 - acc: 0.6268 - val_loss: 0.7698 - val_acc: 0.6123\n",
      "Epoch 48/100\n",
      "20187/20187 [==============================] - 92s 5ms/sample - loss: 0.7394 - acc: 0.6276 - val_loss: 0.7377 - val_acc: 0.6194\n",
      "Epoch 49/100\n",
      "20187/20187 [==============================] - 91s 5ms/sample - loss: 0.7471 - acc: 0.6240 - val_loss: 0.7581 - val_acc: 0.6168\n",
      "Epoch 50/100\n",
      "20187/20187 [==============================] - 91s 4ms/sample - loss: 0.7456 - acc: 0.6239 - val_loss: 0.7311 - val_acc: 0.6239\n",
      "Epoch 51/100\n",
      "20187/20187 [==============================] - 91s 5ms/sample - loss: 0.7404 - acc: 0.6272 - val_loss: 0.7460 - val_acc: 0.6176\n",
      "Epoch 52/100\n",
      "16128/20187 [======================>.......] - ETA: 18s - loss: 0.7457 - acc: 0.6236"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
